{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b949f73-bf9c-4872-82f1-4a9f1da44c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import kurtosis, skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edbcab95-3a8b-46f2-a3a2-10bd9b8bd2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input directory\n",
    "input_directory = '/work/pi_atreya_chakraborty_umb_edu/Captsone/Data'\n",
    "\n",
    "# Define the input file paths\n",
    "clean_analyst_path_weekly = os.path.join(input_directory, 'clean_analyst_weekly.dta')\n",
    "clean_analyst_path_monthly = os.path.join(input_directory, 'clean_analyst_monthly.dta')\n",
    "clean_crsp_path = os.path.join(input_directory, 'clean_crsp.dta')\n",
    "\n",
    "# Read the datasets\n",
    "results_df_weekly = pd.read_stata(clean_analyst_path_weekly)\n",
    "results_df_monthly = pd.read_stata(clean_analyst_path_monthly)\n",
    "crsp_data = pd.read_stata(clean_crsp_path)\n",
    "\n",
    "results_df_weekly = results_df_weekly.groupby(['cusip', 'estimid', 'year', 'month', 'week']).first().reset_index()\n",
    "results_df_monthly = results_df_monthly.groupby(['cusip', 'estimid', 'year', 'month']).first().reset_index()\n",
    "\n",
    "# Convert 'ireccd' to numeric, forcing errors to NaN (if any)\n",
    "results_df_monthly['ireccd'] = pd.to_numeric(results_df_monthly['ireccd'], errors='coerce')\n",
    "\n",
    "# Convert 'ireccd' to numeric, forcing errors to NaN (if any)\n",
    "results_df_weekly['ireccd'] = pd.to_numeric(results_df_monthly['ireccd'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87bc1346-f1e7-4488-8c2f-5d1d4d28d460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_792221/1797840993.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  brokers_with_10_years = broker_month_count.groupby('estimid').apply(lambda x: has_10_firms_consecutive_months(x, 10)).reset_index(name='qualifies')\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group by estimid, year, month, and count unique firms (CUSIPs) per month\n",
    "broker_month_count = results_df_monthly.groupby(['estimid', 'year', 'month'])['cusip'].nunique().reset_index(name='firm_count')\n",
    "\n",
    "# Step 2: Check for at least 10 unique firms every month for 10 consecutive years\n",
    "def has_10_firms_consecutive_months(data, num_years=10):\n",
    "    # Sort by year and month\n",
    "    data = data.sort_values(by=['year', 'month'])\n",
    "    \n",
    "    # Check for each rolling window of 120 consecutive months (10 years)\n",
    "    for i in range(len(data) - num_years * 12 + 1):\n",
    "        window = data.iloc[i:i + num_years * 12]\n",
    "        \n",
    "        # Check if there are at least 10 firms in every month of this window\n",
    "        if all(window['firm_count'] >= 10):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Step 3: Filter brokers with at least 10 firms every consecutive month for 10 years\n",
    "brokers_with_10_years = broker_month_count.groupby('estimid').apply(lambda x: has_10_firms_consecutive_months(x, 10)).reset_index(name='qualifies')\n",
    "brokers_with_10_years = brokers_with_10_years[brokers_with_10_years['qualifies']]  # Keep only brokers meeting the criteria\n",
    "qualifying_brokers = brokers_with_10_years['estimid'].tolist()  # List of brokers that qualify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bb1d763-a676-4b48-9089-c54bd1ae0c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADAMS', 'ARGUS', 'ATLANEQU', 'AVONDALE', 'BACHE', 'BAKER', 'BARRING', 'BEAR', 'BERN', 'BLAIR', 'BREAN', 'BRILEY', 'BTIG', 'BUCK', 'BURNS', 'CANACCOR', 'CANTORFZ', 'CAPELEUR', 'CLKA', 'CLUSA', 'CRAIG', 'CRUTTEN', 'DAVIDSON', 'EDWARDS', 'EVERCO', 'FAHN', 'FBOSTON', 'FIRSTALB', 'FRCLAYSC', 'FRIEDMAN', 'GABELLCO', 'GARTNER', 'GHUNTER', 'GKM', 'GOLDMAN', 'GUGGEL', 'HALLUM', 'HILLIARD', 'JANNEY', 'JEFFEREG', 'JOHNRICE', 'JOLSON', 'JPMORGAN', 'KAUFBRO', 'KEEFE', 'LADENBUR', 'LAWRENCE', 'LAZARD', 'LEERINK', 'LEGG', 'LEHMAN', 'LONGBOW', 'MACQUARI', 'MAXIM', 'MCDONALD', 'MCLEOD', 'MERRILL', 'MIDEST', 'MIZUSEC', 'MKEEGAN', 'MKMPARTN', 'MONTSEC', 'MORGAN', 'NEEDHAM', 'NORTHLAN', 'OLMSTEAD', 'OPPEN', 'PACCREST', 'PACGROW', 'PICKERIN', 'PIPER', 'POINT', 'RAYMOND', 'RBCDOMIN', 'ROBINSON', 'SANDLER', 'SCOAST', 'SCOTT', 'SIDOTI', 'STEPHENS', 'STERNE', 'STIFEL', 'SUMMCAP', 'SUSQUEH', 'TDSI', 'THEBENCH', 'UNTERBUR', 'VANKASPR', 'VIRGINIA', 'WEISEL', 'WHEAT', 'WMJM', 'WOLFE', 'WOODGUND']\n"
     ]
    }
   ],
   "source": [
    "print(qualifying_brokers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b9218ce-4a71-4320-9409-083b10df1130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Process `crsp_data` and merge it with `monthly_rec`\n",
    "crsp_data = crsp_data.sort_values(by=['cusip', 'dlycaldt'])\n",
    "crsp_data['year_month'] = crsp_data['dlycaldt'].dt.to_period('M')\n",
    "crsp_data['monthly_avg_cap'] = crsp_data.groupby(['cusip', 'year_month'])['dlycap'].transform('mean')\n",
    "crsp_data['prior_month_avg_cap'] = crsp_data.groupby('cusip')['monthly_avg_cap'].shift()\n",
    "\n",
    "crsp_monthly = crsp_data.groupby(['cusip', 'year', 'month']).agg(\n",
    "    beginning_price=('dlyprc', 'first'),\n",
    "    ending_price=('dlyprc', 'last'),\n",
    "    cusip9=('cusip9', 'first'),\n",
    "    prior_month_avg_cap=('prior_month_avg_cap', 'first'),\n",
    "    month_std=('dlyprc', 'std')\n",
    ").reset_index()\n",
    "\n",
    "crsp_monthly['month_return'] = (crsp_monthly['ending_price'] - crsp_monthly['beginning_price']) / crsp_monthly['beginning_price'] * 100\n",
    "crsp_monthly['month_return_winsorized'] = winsorize(crsp_monthly['month_return'], limits=[0.01, 0.01])\n",
    "crsp_monthly['month_std_winsorized'] = winsorize(crsp_monthly['month_std'], limits=[0.01, 0.01])\n",
    "\n",
    "# Step 5: Assign periods based on the year\n",
    "def assign_period(year):\n",
    "    if 1992 <= year <= 1999:\n",
    "        return 1\n",
    "    elif 2000 <= year <= 2009:\n",
    "        return 2\n",
    "    elif 2010 <= year <= 2019:\n",
    "        return 3\n",
    "    elif 2020 <= year <= 2024:\n",
    "        return 4\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "crsp_monthly['period'] = crsp_monthly['year'].apply(assign_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "defcd53c-4a29-43f8-8fb6-996f94c87401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_792221/3106360696.py:71: InvalidColumnName: \n",
      "Not all pandas column names were valid Stata variable names.\n",
      "The following replacements have been made:\n",
      "\n",
      "    Year-Month_x   ->   Year_Month_x\n",
      "    Mom      ->   Mom___\n",
      "    Year-Month_y   ->   Year_Month_y\n",
      "    Year-Month   ->   Year_Month\n",
      "    Mkt-RF   ->   Mkt_RF\n",
      "    Year-Month_ff5   ->   Year_Month_ff5\n",
      "    Mkt-RF_ff5   ->   Mkt_RF_ff5\n",
      "\n",
      "If this is not what you expect, please make sure you have Stata-compliant\n",
      "column names in your DataFrame (strings only, max 32 characters, only\n",
      "alphanumerics and underscores, no Stata reserved words)\n",
      "\n",
      "  final_df.to_stata(\"rec_return_broker.dta\")\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to hold dataframes for each broker\n",
    "broker_dfs = []\n",
    "\n",
    "# Loop through each qualifying broker and run the analysis\n",
    "for broker_id in qualifying_brokers:\n",
    "    \n",
    "    # Step 1: Filter results_df_monthly for the current broker\n",
    "    broker_df = results_df_monthly[results_df_monthly['estimid'] == broker_id].copy()\n",
    "\n",
    "    # Step 2: Recode 'ireccd' to imply more favorable recommendations\n",
    "    broker_df['ireccd'] = 6 - broker_df['ireccd']\n",
    "\n",
    "    # Step 3: Obtain the recommendations for each firm by the current broker (not the average)\n",
    "    monthly_rec = broker_df.groupby(['cusip', 'year', 'month']).agg(\n",
    "        avg_ireccd=('ireccd', 'first'),\n",
    "        sic=('sic', 'first'),\n",
    "        ff_5=('ff_5', 'first'),\n",
    "        ff_10=('ff_10', 'first'),\n",
    "        ff_17=('ff_17', 'first'),\n",
    "        ff_48=('ff_48', 'first')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Step 6: Merge `monthly_rec` with `crsp_monthly`\n",
    "    rec_return = pd.merge(monthly_rec, crsp_monthly[['cusip', 'year', 'month', 'month_return', 'month_return_winsorized', 'month_std', 'month_std_winsorized', 'cusip9', 'prior_month_avg_cap']], \n",
    "                          on=['cusip', 'year', 'month'], \n",
    "                          how='left')\n",
    "\n",
    "    # Step 7: Add the `broker` column (the `estimid` of the current broker)\n",
    "    rec_return['broker'] = broker_id\n",
    "\n",
    "    # Step 8: Append the dataframe to the list\n",
    "    broker_dfs.append(rec_return)\n",
    "\n",
    "# Step 9: Concatenate all broker dataframes into one final dataframe\n",
    "final_df = pd.concat(broker_dfs, ignore_index=True)\n",
    "\n",
    "# Step 10: Merge with additional datasets if needed and export\n",
    "# File paths\n",
    "ff_momentum_path = f\"{input_directory}/FF_Momentum_Monthly.csv\"\n",
    "ff_str_path = f\"{input_directory}/FF_STR_Monthly.csv\"\n",
    "ff3_path = f\"{input_directory}/FF3_Monthly.csv\"\n",
    "ff5_path = f\"{input_directory}/FF5_Monthly.csv\"\n",
    "q_factor_path = f\"{input_directory}/q_factor.csv\"\n",
    "\n",
    "# Load additional datasets\n",
    "ff_momentum = pd.read_csv(ff_momentum_path)\n",
    "ff_str = pd.read_csv(ff_str_path)\n",
    "ff3 = pd.read_csv(ff3_path)\n",
    "ff5 = pd.read_csv(ff5_path)\n",
    "q_factor = pd.read_csv(q_factor_path)\n",
    "\n",
    "# Add year and month columns to each file\n",
    "def add_year_month(df, col_name='Year-Month'):\n",
    "    df['year'] = df[col_name].astype(str).str[:4].astype(int)\n",
    "    df['month'] = df[col_name].astype(str).str[4:].astype(int)\n",
    "    return df\n",
    "\n",
    "ff_momentum = add_year_month(ff_momentum)\n",
    "ff_str = add_year_month(ff_str)\n",
    "ff3 = add_year_month(ff3)\n",
    "ff5 = add_year_month(ff5)\n",
    "\n",
    "# Merge the four datasets into final_df using lowercase year and month\n",
    "final_df = pd.merge(final_df, ff_momentum, on=['year', 'month'], how='left')\n",
    "final_df = pd.merge(final_df, ff_str, on=['year', 'month'], how='left')\n",
    "final_df = pd.merge(final_df, ff3, on=['year', 'month'], how='left', suffixes=('', '_ff3'))\n",
    "final_df = pd.merge(final_df, ff5, on=['year', 'month'], how='left', suffixes=('', '_ff5'))\n",
    "final_df = pd.merge(final_df, q_factor, on=['year', 'month'], how='left', suffixes=('', '_q'))\n",
    "\n",
    "# Export the final result\n",
    "final_df.to_stata(\"rec_return_broker.dta\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
